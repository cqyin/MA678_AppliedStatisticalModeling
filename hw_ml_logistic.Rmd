---
title: "MA678 homework 08"
author: "Name"
date: "November 10, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="pdf",fig.align  = 'center')
library(ggplot2)
library(knitr)
library(gridExtra)
library(arm)
library(data.table)
library(foreign)
library(car)
library(stringr)
library(rstan)
library(zoo)

coefplot_my <- function(model){
  toc <- summary(model)$coef
  tab <- data.table(toc)
  tab$coefnames <- rownames(toc)
  tab<-subset(tab,coefnames!="(Intercept)")
  ggplot(tab) + geom_point() + 
    geom_pointrange(aes(ymax = Estimate + 2*`Std. Error` , ymin=Estimate - 2*`Std. Error`),lwd=0.2)+
    aes( y=Estimate, x=coefnames)+geom_pointrange(aes(ymax = Estimate + `Std. Error` , ymin=Estimate - `Std. Error`))+
    geom_hline(yintercept=0,lty	=2)+xlab("coefficients")+ylab("estimate +/- 2 Std.Error")+
    scale_x_discrete(limits=tab$coefnames)+ 
    coord_flip()
}
```


# presidential preference and income for the 1992 election

The folder `nes` contains the survey data of presidential preference and income for the 1992 election analyzed in Section 5.1, along with other variables including sex, ethnicity, education, party identification, political ideology, and state.

1. Fit a logistic regression predicting support for Bush given all these inputs except state. Consider how to include these as regression predictors and also consider possible interactions.

```{r,echo=FALSE}
library(foreign)
brdata <- read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/nes/nes5200_processed_voters_realideo.dta",convert.factors=F)
brdata <- brdata[is.na(brdata$black)==FALSE&is.na(brdata$female)==FALSE&is.na(brdata$educ1)==FALSE
                 &is.na(brdata$age)==FALSE&is.na(brdata$income)==FALSE&is.na(brdata$state)==FALSE,]
kept.cases <- 1952:2000
matched.cases <- match(brdata$year, kept.cases)
keep       <- !is.na(matched.cases)
data       <- brdata[keep,]
plotyear   <- unique(sort(data$year))
year.new   <- match(data$year,unique(data$year))
n.year     <- length(unique(data$year))
income.new <- data$income - 3
age.new    <- (data$age-mean(data$age))/10
y          <- data$rep_pres_intent
data       <- cbind(data, year.new, income.new, age.new, y)
nes.year   <- data[,"year"]
age.discrete <- as.numeric (cut (data[,"age"], c(0,29.5, 44.5, 64.5, 200)))
race.adj     <- ifelse (data[,"race"]>=3, 1.5, data[,"race"])
data        <- cbind (data, age.discrete, race.adj)

data$female <- data[,"gender"] - 1
data$black <- ifelse (data[,"race"]==2, 1, 0)
data$rvote <- ifelse (data[,"presvote"]==1, 0, ifelse(data[,"presvote"]==2, 1, NA))

```

2.  Now formulate a model predicting support for Bush given the same inputs but allowing the intercept to vary over state. Fit using `lmer()` and discuss your results.

```{r,echo=FALSE}

```

3. Create graphs of the probability of choosing Bush given the linear predictor associated with your model separately for each of eight states as in Figure 14.2.

```{r,echo=FALSE}

```



## Three-level logistic regression: 

the folder `rodents` contains data on rodents in a sample of New York City apartments.

1. Build a varying intercept logistic regression model (varying over buildings) to predict the presence of rodents (the variable rodent2 in the dataset) given indicators for the ethnic groups (race) as well as other potentially relevant predictors describing the apartment and building. Fit this model using lmer() and interpret the coefficients at both levels.

```{r,echo=FALSE}
apt.subset.data <- read.table ("http://www.stat.columbia.edu/~gelman/arm/examples/rodents/rodents.dat", header=TRUE)
apt_dt <- data.table(apt.subset.data)

invisible(apt_dt[,asian := race==5 | race==6 | race==7])
invisible(apt_dt[,black := race==2])
invisible(apt_dt[,hisp  := race==3 | race==4])

``` 

2. Now extend the model in (1) to allow variation across buildings within community district and then across community districts. Also include predictors describing the community districts. Fit this model using lmer() and interpret the coefficients at all levels.

```{r,echo=FALSE}


```

3. Compare the fit of the models in (1) and (2).

```{r,echo=FALSE}


```

## Item-response model: 

the folder `exam` contains data on students' success or failure (item correct or incorrect) on a number of test items. Write the notation for an item-response model for the ability of each student and level of difficulty of each item.

```{r,echo=FALSE}
# Read in the data from an excel-format ".csv" file
exam.data.raw <- read.table("http://www.stat.columbia.edu/~gelman/arm/examples/exam/mtermgrades.txt", header=FALSE)

```

##  Multilevel logistic regression 

The folder `speed.dating` contains data from an experiment on a few hundred students that randomly assigned each participant to 10 short dates with participants of the opposite sex (Fisman et al., 2006). For each date, each person recorded several subjective numerical ratings of the other person (attractiveness, compatibility, and some other characteristics) and also wrote down whether he or she would like to meet the other person again. Label $y_{ij} = 1$ if person $i$ is interested in seeing person $j$ again $0$ otherwise.
And $r_{ij1},\dots, r_{ij6}$ as person $i$'s numerical ratings of person $j$ on the dimensions of attractiveness, compatibility, and so forth.
Please look at 
http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/Speed%20Dating%20Data%20Key.doc
for details.

```{r}
dating<-fread("http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/Speed%20Dating%20Data.csv")

```

1. Fit a classical logistic regression predicting $Pr(y_{ij} = 1)$ given person $i$'s 6 ratings of person $j$. Discuss the importance of attractiveness, compatibility, and so forth in this predictive model.

```{r}

```

2. Expand this model to allow varying intercepts for the persons making the evaluation; that is, some people are more likely than others to want to meet someone again. Discuss the fitted model.

```{r}

```

3. Expand further to allow varying intercepts for the persons being rated. Discuss the fitted model.

```{r}

```

4. You will now fit some models that allow the coefficients for attractiveness, compatibility, and the other attributes to vary by person. Fit a no-pooling model: for each person i, fit a logistic regression to the data $y_{ij}$ for the 10 persons j whom he or she rated, using as predictors the 6 ratings $r_{ij1},\dots,r_{ij6}$ . (Hint: with 10 data points and 6 predictors, this model is difficult to fit. You will need to simplify it in some way to get reasonable fits.)
```{r}

```


5. Fit a multilevel model, allowing the intercept and the coefficients for the 6 ratings to vary by the rater i.

```{r}

```

6. Compare the inferences from the multilevel model in (5) to the no-pooling model in (4) and the complete-pooling model from part (1) of the previous exercise.

```{r}

```



## The well-switching data described in Section 5.4 are in the folder arsenic.

1. Formulate a multilevel logistic regression model predicting the probability of switching using log distance (to nearest safe well) and arsenic level and allowing intercepts to vary across villages. Fit this model using `lmer()` and discuss the results.

```{r,echo=FALSE}

village <- read.delim("http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/Village.txt",header=TRUE,dec = ",")
as.double(gsub(",","",village$Best.Longitude))
ggplot(village)+geom_jitter()+aes(x=long,y=lat)
wells <- read.table("http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat", header=TRUE)
wells <- read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/all.dta",convert.factors=F)
wells_f <- read.csv("http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/All.csv", header=TRUE)
wells_f <- read.csv("http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/fulldata1.csv", header=TRUE)

```

2. Extend the model in (1) to allow the coefficient on arsenic to vary across village, as well. Fit this model using `lmer()` and discuss the results.

```{r,echo=FALSE}


```

3. Create graphs of the probability of switching wells as a function of arsenic level for eight of the villages.

```{r,echo=FALSE}


```

4. Compare the fit of the models in (1) and (2).

```{r,echo=FALSE}


```
